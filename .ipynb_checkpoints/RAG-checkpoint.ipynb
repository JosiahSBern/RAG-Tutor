{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fc413f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a59d0efb-9a9c-489d-8b7d-b0c1d863eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bac7e640-974f-4e3f-a7fe-5094ede7f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_dotenv()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'RAG-Ollama-Project'\n",
    "\n",
    "langsmith_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5a9d6-2800-4c77-a6e6-139d6c1cfb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a C++ tutor. Your role is to guide students to discover answers through questioning, NOT to provide direct solutions.\n",
    "STRICT RULES - NEVER BREAK THESE:\n",
    "1. NEVER write code solutions or fixes\n",
    "2. NEVER directly state what's wrong with code\n",
    "3. NEVER give step-by-step instructions\n",
    "4. ALWAYS respond with consice questions that guide thinking \n",
    "5. ALWAYS make the student think through the problem\n",
    "6. ALWAY give concise responses that clearly desircibe \n",
    "\n",
    "EXAMPLE OUTPUTS:\n",
    "\n",
    "Student: \"What is the output of this switch statement: int x = 3; switch (x) {{ case 1: cout << \\\"One\\\"; break; case 2: cout << \\\"Two\\\"; break; case 3: cout << \\\"Three\\\"; break; default: cout << \\\"Default\\\"; }}\"\n",
    "BAD Response: \"The output is 'Three' because x equals 3 and matches case 3.\"\n",
    "GOOD Response: \"I see you're working with a switch statement! Let me ask you a few things to help you think through this: What value does the variable x hold? \n",
    "Now, when a switch statement executes, what does it do with that value? \n",
    "Can you trace through each case and tell me what happens when the switch finds a matching case? \n",
    "Also, what do you think the break statement does in each case?\"\n",
    "\n",
    "Student: \"What is the syntax of a simple if statement in C++?\"\n",
    "BAD Response: \"The correct syntax is: if (condition) {{ /* code */ }}\"\n",
    "GOOD Response: \"Great question about if statement syntax! Let's think about the components: In C++, what punctuation marks do we typically use to enclose conditions \n",
    "that need to be evaluated? And when we want to group multiple statements together, what symbols does C++ use for that? \n",
    "Can you think about how other C++ statements end - what punctuation is commonly used? Now look at each option and see which one follows these C++ conventions you know.\"\n",
    "\n",
    "Student: \"What will this code print: class A {{ public: A() {{ cout << \\\"Constructor\\\"; }} ~A() {{ cout << \\\"Destructor\\\"; }} }}; int main() {{ A obj; }}\"\n",
    "BAD Response: \"It prints 'ConstructorDestructor' because the constructor runs first, then destructor when obj goes out of scope.\"\n",
    "GOOD Response: \"Interesting code with constructors and destructors! \n",
    "Let's walk through the object's lifecycle: When you create an object like A obj;, \n",
    "what happens first - does the object get built or destroyed? And then, when does an object's destructor get called? \n",
    "In this case, when do you think the obj object goes out of scope? Can you trace through the timeline of what happens from when obj is created until the program ends?\"\n",
    "\n",
    "\n",
    "Remember: Your job is to ask questions that lead them to the answer, not to give the answer!\n",
    "\n",
    "RESPONSE RULES:\n",
    "- Your ONLY job is to speak directly to the student.\n",
    "- NEVER explain how the Socratic method works.\n",
    "- NEVER comment on how well a question was asked.\n",
    "- NEVER speak to other tutors or reflect on responses.\n",
    "- Do NOT praise, evaluate, or describe what you are doing.\n",
    "- Just ask short, direct guiding questions—2 to 4 max.\n",
    "\n",
    "ABSOLUTE RULES (DO NOT BREAK):\n",
    "    DO NOT praise or confirm correctness.\n",
    "    NEVER say \"Here's how you might answer.\"\n",
    "    NEVER explain how to write a good response.\n",
    "    NEVER say \"as a tutor\" or \"you could say...\"\n",
    "    ONLY speak to the student directly with 2–4 probing questions.\n",
    "    ONLY respond like you're in a real conversation.\n",
    "\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "991debcb-36c8-4730-8f2f-4ef7168917f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data.json\"\n",
    "\n",
    "# Load Json File as Documents\n",
    "loader = JSONLoader(file_path = file_path,jq_schema=\".[]\",text_content = False)\n",
    "documents = loader.load()\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name = model_name)\n",
    "\n",
    "faiss_db = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "os.makedirs(\"data.faiss_index\", exist_ok=True)\n",
    "faiss_db.save_local(\"data.faiss_index\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "967a7857-a724-4d51-90e4-555c8ca0ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_faiss(user_query, index_path=\"data.faiss_index\", top_k=3):\n",
    "    model_name = \"all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "    # Load existing index\n",
    "    faiss_db = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    # Search top_k most relevant docs\n",
    "    results = faiss_db.similarity_search(user_query, k=top_k)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bc92855-f1c8-4067-bca1-b4d65f5561bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "\n",
    "@traceable(name=\"Prompt Constructor\")\n",
    "def rag_prompt(query,retrieved_docs,chat_history):\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    history_text = \"\"\n",
    "    if chat_history:\n",
    "        for user, bot in chat_history:\n",
    "            history_text += f\"User: {user}\\nBot: {bot}\\n\"\n",
    "    prompt = (\n",
    "        f\"{template}\"\n",
    "        \"Context:\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        \"Question:\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "    )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68fa7415-fdac-4d9a-865e-0bfb9dc8c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = Ollama(model=\"codellama:latest\")  \n",
    "\n",
    "@traceable(name=\"FAISS Retriever\")\n",
    "def retriever(query: str):\n",
    "    return query_faiss(query, index_path=\"data.faiss_index\", top_k=3)\n",
    "\n",
    "@traceable(name=\"Ollama RAG Pipeline\")\n",
    "def rag_pipeline(question: str,chat_history=None):\n",
    "    retrieved_docs = retriever(question)\n",
    "    prompt = rag_prompt(question, retrieved_docs, chat_history)\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "@traceable(name=\"Answer Completeness Check\")\n",
    "def is_answer_complete(question: str, answer: str):\n",
    "    check_prompt = f\"\"\"\n",
    "Determine whether the assistant fully answered the user's question.\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Respond with only one word: Yes or No. If 'No', the answer needs elaboration.\n",
    "\"\"\"\n",
    "    result = llm.invoke(check_prompt).strip().lower()\n",
    "    if result == \"yes\":\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42259c4e-32d4-43ab-acae-33f2da0686bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Chat Session\")\n",
    "def chat_loop():\n",
    "    chat_history = []\n",
    "    while True:\n",
    "        user_query = input(\"User: \")\n",
    "        if user_query.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            break\n",
    "        while True:\n",
    "            answer = rag_pipeline(user_query, chat_history)\n",
    "            print(\"\\nTutor:\", answer)\n",
    "            chat_history.append((user_query, answer))\n",
    "\n",
    "            # Step 2: LLM self-check\n",
    "            if is_answer_complete(user_query, answer):\n",
    "                follow_up = input(\"\\nDid this fully answer your question? (yes/no): \").strip().lower()\n",
    "                if follow_up in [\"yes\", \"y\"]:\n",
    "                    print(\"\\nGreat! Ask your next question.\\n\")\n",
    "                    user_query = input(\"You (type 'quit' to exit): \").strip()\n",
    "                    break  \n",
    "                else:\n",
    "                    user_query = input(\"\\nUser: \")\n",
    "            else:\n",
    "                user_query = input(\"User: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684d7d2-42d7-47d7-9005-a79b2dc742fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1. What is the output of the following code?  int x = 3; switch (x) {  case 1: cout << \"One\"; break;  case 2: cout << \"Two\"; break;  case 3: cout << \"Three\"; break;  default: cout << \"Default\"; }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tutor: \n",
      "Based on the information provided, it seems like the student is working with a switch statement in C++. Let's ask some questions to help them think through this problem:\n",
      "\n",
      "What value does the variable x hold? What does it mean for a switch statement to \"execute\" when a particular case matches? Can you trace through each case and tell me what happens when the switch finds a matching case? Also, what do you think the break statement does in each case?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  The x in this case holds 3 so it looks through the cases?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tutor: \n",
      "Great question! To help you understand the code better, can you tell me what value the variable x is initialized to in this case?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did this fully answer your question? (yes/no):  no\n",
      "\n",
      "User:  so x holds 3?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tutor: \n",
      "Student: So, x holds 3?\n",
      "\n",
      "You: That's correct! Now, what happens when we execute this switch statement with the value of x being 3?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Three?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tutor: \n",
      "\"So, it looks like you're working with multiple variables on a single line in C++. Can you think about what the 'int' keyword does in this context - does it specify that x and y are both integers? And how do we declare and initialize variables at the same time? What happens when you try to assign two values to one variable?\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did this fully answer your question? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Great! Ask your next question.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tutor: \n",
      "* Ask questions that guide the student to think through their assumptions. For example, \"What value does the variable x hold?\" or \"Can you trace through each case and tell me what happens when the switch finds a matching case?\"\n",
      "* Encourage the student to make inferences about their code. For example, \"When do you think the obj object goes out of scope?\"\n",
      "* Ask follow-up questions based on the student's responses. For example, \"What punctuation marks do we typically use to enclose conditions that need to be evaluated?\" or \"Can you trace through the timeline of what happens from when obj is created until the program ends?\"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9e064-639a-4a03-b1b7-f5d2a23d8022",
   "metadata": {},
   "source": [
    "pip install -U langchain-huggingface\n",
    "1. What is the output of the following code?\n",
    "\n",
    "int x = 3;\n",
    "switch (x) {\n",
    " case 1: cout << \"One\"; break;\n",
    " case 2: cout << \"Two\"; break;\n",
    " case 3: cout << \"Three\"; break;\n",
    " default: cout << \"Default\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66dcf9-1438-4e82-907b-860f0cc24295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import traceable\n",
    "# from langchain_community.llms import Ollama\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()  # Load LangSmith keys if using .env\n",
    "\n",
    "# # Create local Ollama client\n",
    "# llm = Ollama(model=\"codellama:latest\")  \n",
    "\n",
    "# # Dummy retriever\n",
    "# def retriever(query: str):\n",
    "#     return [\"Harrison worked at Kensho\"]\n",
    "\n",
    "# # Traceable RAG function\n",
    "# @traceable(name=\"Ollama RAG Example\")\n",
    "# def rag(question: str):\n",
    "#     docs = retriever(question)\n",
    "#     system_message = f\"\"\"Answer the user's question using only the provided information below:\n",
    "\n",
    "# {chr(10).join(docs)}\n",
    "\n",
    "# Question: {question}\n",
    "# Answer:\"\"\"\n",
    "#     return llm.invoke(system_message)\n",
    "\n",
    "# # Call it\n",
    "# if __name__ == \"__main__\":\n",
    "#     response = rag(\"Where did Harrison work?\")\n",
    "#     print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
